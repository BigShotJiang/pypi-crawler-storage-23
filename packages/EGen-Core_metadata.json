{
  "name": "EGen-Core",
  "version": "1.0.1",
  "summary": "EGen-Core — The Athena Project (2025–2026). A high-performance, memory-efficient inference engine for large language models. Run 70B+ parameter models on a single 4GB GPU without quantization, distillation, or pruning. Supports layer-wise sharded inference, 4-bit/8-bit block-wise compression, multi-architecture auto-detection, and Apple Silicon (MLX) acceleration. Developed by ErebusTN.",
  "author": "ErebusTN",
  "license": null,
  "home_page": "https://github.com/ErebusTN/EGen-Core",
  "download_filename": "egen_core-1.0.1.tar.gz",
  "download_time": "2026-02-27T20:22:26.627392",
  "package_url": "https://pypi.org/project/EGen-Core/"
}